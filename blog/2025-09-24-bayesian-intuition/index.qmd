---
title: "Bayesian Intuition for Beginners with Interactive Web Applications"
format: 
  html:
    # Code styling
    code-fold: false 
    code-summary: "Show code"
    code-tools: false 
    code-copy: false 
    code-overflow: wrap
    css: styles.css
    # sided links:
    other-links: 
      - text: Beta Distribution Visualizer
        href: https://isaacforzan.github.io/ShinyApps/beta-distribution/
      - text: Bayesian Coin Toss Simulation
        href: https://isaacforzan.github.io/ShinyApps/conjugate-beta-model/
  
    
date: 2025-09-25

code-block-bg: false 
code-block-border-left: "#31BAE9"

bibliography: references.bib
execute:
  echo: false       # Show code 
  warning: false   # Hide warnings
  message: false   # Hide messages
  results: false    # Show results (output)
  output: TRUE      # Show output
editor_options: 
  chunk_output_type: console
---

```{r}
library(tidyverse)
library(gganimate)
library(gifski)
library(rmarkdown)
```

# Introduction

My journey into statistics is an unusual case. I got an introduction of the classical test statistics ($z, \space t, \space tt, \chi^{2}, etc...$) for experimental design class. I liked it a lot but I wasn't satisfied and later on it felt that I needed a solid background of statistics; YouTube's algorithm noticed it and showed an incredible video [@lenox2016] that explains this school of thought of statistics called Bayesianism. It convinced me. The result: I learned Bayesian statistics first and then Frequentists stats.

Recently I have been going deep into Frequentist approaches of decision making given that it is what must of people know. But, I always get this feeling of insatisfaction, maybe even contempt. Reading a paper by @efron1986why called "*Why Isn't Everyone a Bayesian?*" --- great article --- inspired me to make my first Bayesian blog about the classical coin flipping scenario seeing form the lens of Bayesianism. It is really intuitive and playing with the web applications will make you have a better understanding. Hope you like it. My objective is to get you into the *inverse probability* rabbit hole.

This for beginners and **I** **won't be using any math**. If you want to know what is going on behind the scenario check @pml2Book. The web applications for playing are in the extra links section at the right side of your the screen.

# Coin flipping

You are a pre-teenager in a children party like back in the days. It is late and your boredom is starting to become uncomfortable even for your friends. You get an idea, "Let's bet playing the coin", "Yes!!"

## 1) Setting up your belief

You know it is a dumb game because you know there is 50/50 chance of winning. The is no skill involvement. But okay, you proposed it so you have to play along. You will be betting on heads. Here as a Bayesian we define our beliefs of the probability that it falls heads, which is 50%:

```{r}
df1 <- data.frame(
  x = seq(0,1,0.1),
  y = seq(0,1,0.1)
)
ggplot(df1, aes(x, y)) +
  geom_blank() +
  geom_segment(aes(x = 0.5, xend = 0.5, y = 0, yend = 1), linewidth = 1, color = "blue3") +
  labs(
    title = "Our Beliefs of the probability of the coin landing on heads",
    x = "Heads",
    y = "Density"
  ) + theme_bw()
  
```

Here we are saying that you are 100% sure that the probability is 50%. This isn't true. There is some variation produced from factory in the shape of the coin, or any other reason you can think about. So you define a more accurate belief:

```{r}
df2 <- tibble(
  x = seq(0,1,0.01),
  y = dbeta(x, 100, 100)
) 
ggplot(df2, aes(x, y)) +
  geom_area(fill = "lightblue", alpha = 0.5) +  # More transparent
  geom_line(color = "blue", linewidth = 1) +
  labs(
    title = "Our Beliefs of the probability of the coin landing on heads",
    x = "Heads",
    y = "Probability Density"
  ) + theme_bw()
```

Here we are saying that we are still pretty sure that the probability is 50%. Imagine that we are really clueless, and we really don't know. This is how we would represent our belief:

```{r}
tibble(
  x = seq(-0.1,1.1 ,0.01),
  y = dbeta(x, 1, 1)
) |> 
  ggplot(aes(x, y)) +
  geom_area(fill = "lightblue", alpha = 0.5) +  # More transparent
  geom_line(color = "blue", linewidth = 1) +
  labs(
    title = "Our Beliefs of the probability of the coin falling into heads",
    x = "Heads",
    y = "Probability Density"
  ) + theme_bw()
```

Why does this expression translates into cluelessness? By assigning equal probability to everything you are saying that anything can happen, it is an expression of complete uncertainty[^1]

[^1]: There is better ways to express cluelessness in Bayesian statistics. This non-informative uniform prior is saying something at the end by assigning equal probabilities to anything. That's something! There is others non-informative priors that really try not saying something, like Jeffreys prior. More info about noninformative priors in @pml2Book

How do we modify our beliefs? We use something called probability density functions. The normal distribution is a probability density function. They contain something called hyperparameters that we use, in this case, to modify state our beliefs and modifying it by changing its values. In the next animation it shows how the beta distribution, which is the probability density function we have used in the previous figures, changes when the hyperparameters are modified.

![Beta Distribution Animation](beta_animation.gif)

Next it's your turn to modified the hyperparameters and get a sense of how the beta distribution works. Go to the link play at the bottom right side of the screen with the name "**Beta Distribution Visualizer**". Play with the app, and think how would YOU define your beliefs over a coin.

## 2) Updating your belief

The game is about to start and suddenly a friendly voice says "I bet 100\$ on Tails but with my coin". You know that tone, it is your tricky cheater of a cousin. You know he has some biased coins in his closet. Your belief over the coin changes rapidly:

```{r}
tibble(
  x = seq(0, 1, 0.01),
  y = dbeta(x, 2.2, 5.9)
) |> 
  ggplot(aes(x, y))+
  geom_area(fill = "lightblue", alpha = 0.5) +  # More transparent
  geom_line(color = "blue", linewidth = 1) +
  labs(
    title = "Changed belief of the probability of the coin falling landing on heads",
    x = "Heads",
    y = "Probability Density"
  ) + theme_bw()
```

You just think he is going to cheat, and you are assigning smaller probability the coin being fair. The only way to changing our belief is by playing it, because maybe you are wrong and it is really a fair coin by landing 50/50 heads and tails. Let's play 10 times:

```{r}
params <- list(
  alpha = 2.2,
  beta  = 5.9,
  n = 10 # sample size
)

set.seed(2025) 
data <- rbinom(n = 10, size = 1, p = 0.5) # theta = {H = 1, T = 0}

plot_data <- tibble(
  x = seq(0, 1, 0.01), 
  prior = dbeta(x, params$alpha, params$beta),
  posterior = dbeta(x,
                params$alpha + sum(data),
                params$beta + params$n - sum(data))
) |> 
  pivot_longer(cols = c(prior, posterior), 
               names_to = "distribution", 
               values_to = "density")

conjugate_plot <- ggplot(plot_data, aes(x = x, y = density, color = distribution)) +
  geom_line(size = 1.5, alpha = 0.8) +
  geom_area(aes(fill = distribution), alpha = 0.2, position = "identity") +
  
  scale_color_manual(
    values = c("prior" = "blue", "posterior" = "red4"),
    labels = c("Prior", "Posterior")
  ) +
  scale_fill_manual(
    values = c("prior" = "lightblue", "posterior" = "red"),
    labels = c("Prior", "Posterior")
  ) +
  
  labs(
    title = "Bayesian Inference: Prior vs Posterior",
    subtitle = paste(sum(data), "heads in", params$n, "trials"),
    x = "Probability Parameter (Heads)",
    y = "Density"
  ) +
  
  theme_bw() +
  theme(
    plot.title = element_text(face = "bold", hjust = 0.5),
    plot.subtitle = element_text(hjust = 0.5, color = "gray50"),
    legend.position = "top",
    panel.grid = element_line(color = "gray95")
  )

print(conjugate_plot)
```

Turns out your prior belief, which stated he would cheat, isn't correct. He used a fair coin. I guess sometimes people change.

## Bayesian statistics

This is the essence of Bayesian statistics: a method in which we update our beliefs over something given evidence. The updated evidence is what is called the **posterior** and you can think of it as a compromise between our prior beliefs and the data.

$$
posterior â‰ˆ data \space * \space prior
$$ Please enter to the link at the bottom right side of the screen with the name "**Bayesian Coin Toss Simulation**" to get a sense how posterior is formed given evidence (data). If you have a very strong belief, it is probable that the prior overwhelms the data, so chose wisely your prior.

# Further readings

This is just the begging of the Bayesian paradigm. And I hope you like it. If you really like it I and you are a true beginner I recommend @kruschke2015doing (I left the link for the .pdf), the author explains every single topic exquisitely, and it is all about doing data analysis for the frequent practitioner, if you are not really into math, this is the book. If you want something more rigorous, more for statistician @gelman2013bayesian is the bible for Bayesians (in the url page you can downloaded for free). If you are interested and don't know where to start, don't hesitate in contact me.
